import serial
import csv
import time
import os
import pandas as pd
import numpy as np
import joblib
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.svm import SVC
from collections import deque
from sklearn.metrics import classification_report, confusion_matrix
import warnings
warnings.filterwarnings("ignore")

# ==============================
# === CONFIGURACI√ìN GLOBAL ===
# ==============================
PUERTO = "COM3"        # ‚ö†Ô∏è Cambia seg√∫n tu puerto serial
BAUDIOS = 115200
CARPETA_DATOS = "AI/data/guante"
CARPETA_MODELOS = "AI/modelos"
os.makedirs(CARPETA_DATOS, exist_ok=True)
os.makedirs(CARPETA_MODELOS, exist_ok=True)

# ==============================
# === FUNCI√ìN: GENERAR FEATURES ===
# ==============================
def generar_features(df):
    X = df[["Menique", "Anular", "Medio", "Indice", "Gordo"]].copy()

    # Derivadas simples (magnitud de cambio)
    for col in X.columns:
        X[col + "_d1"] = X[col].diff().abs().fillna(0)

    # Ratios entre dedos (para capturar relaciones relativas)
    eps = 1e-3
    X["ratio_I_G"] = X["Indice"] / (X["Gordo"] + eps)
    X["ratio_M_A"] = X["Medio"] / (X["Anular"] + eps)
    X["ratio_M_I"] = X["Medio"] / (X["Indice"] + eps)
    X["ratio_A_M"] = X["Anular"] / (X["Medio"] + eps)

    return X

# ==============================
# === FUNCI√ìN: RECOLECTAR DATOS ===
# ==============================
def recolectar_datos():
    letras = list("ABCDEF")   # üî§ Solo letras A-F
    muestras_por_letra = 400  # üî¢ N√∫mero fijo por letra

    puerto = input(f"üîå Puerto serial [{PUERTO}]: ").strip() or PUERTO
    ser = serial.Serial(puerto, BAUDIOS)
    time.sleep(2)

    for letra in letras:
        archivo_salida = os.path.join(CARPETA_DATOS, f"{letra}.csv")
        print(f"\nüì∏ Recolectando {muestras_por_letra} muestras para letra '{letra}'...")
        print("üëâ Realiza la se√±a ahora. Esperando 3 segundos...")
        time.sleep(3)

        with open(archivo_salida, "w", newline="") as f:
            writer = csv.writer(f)
            writer.writerow(["Menique", "Anular", "Medio", "Indice", "Gordo", "Letra"])
            contador = 0

            while contador < muestras_por_letra:
                try:
                    linea = ser.readline().decode().strip()
                    if not linea:
                        continue
                    valores = linea.split(",")
                    if len(valores) != 5:
                        continue
                    valores = [float(v) for v in valores]
                    if any(np.isnan(valores)) or any(x < 0 or x > 1 for x in valores):
                        continue
                    writer.writerow(valores + [letra])
                    contador += 1
                    print(f"\rüìà {letra}: {contador}/{muestras_por_letra}", end="")
                except Exception as e:
                    print("‚ö†Ô∏è Error:", e)
                    continue

        print(f"\n‚úÖ Recolecci√≥n para '{letra}' completada y guardada en {archivo_salida}")
        time.sleep(1)

    ser.close()
    print("\nüéØ Recolecci√≥n de todas las letras finalizada.")

# ==============================
# === FUNCI√ìN: ENTRENAR MODELO ===
# ==============================
def entrenar_modelo():
    print("\nüß† Iniciando entrenamiento del modelo mejorado (SVC + escalado + features)...")

    letras_validas = {"A", "B", "C", "D", "E", "F"}
    archivos = [
        os.path.join(CARPETA_DATOS, f)
        for f in os.listdir(CARPETA_DATOS)
        if f.endswith(".csv") and f.split(".")[0] in letras_validas
    ]
    if not archivos:
        print("‚ö†Ô∏è No hay datos para entrenar (A-F). Ejecuta la recolecci√≥n primero.")
        return

    df = pd.concat([pd.read_csv(f) for f in archivos], ignore_index=True)
    X = generar_features(df)
    y = df["Letra"]

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

    pipeline = Pipeline([
        ("scaler", StandardScaler()),
        ("svc", SVC(probability=True))
    ])

    parametros = {
        "svc__C": [0.5, 1, 2],
        "svc__gamma": ["scale", 0.1, 0.01],
        "svc__kernel": ["rbf"]
    }

    grid = GridSearchCV(pipeline, parametros, cv=4, n_jobs=-1)
    grid.fit(X_train, y_train)

    modelo = grid.best_estimator_
    print(f"üèÜ Mejor configuraci√≥n: {grid.best_params_}")

    y_pred = modelo.predict(X_test)
    print("\nüìä Reporte de clasificaci√≥n:\n")
    print(classification_report(y_test, y_pred))
    print("\nüìâ Matriz de confusi√≥n:")
    print(confusion_matrix(y_test, y_pred))

    precision = modelo.score(X_test, y_test)
    print(f"\n‚úÖ Precisi√≥n final del modelo: {precision * 100:.2f}%")

    os.makedirs(CARPETA_MODELOS, exist_ok=True)
    joblib.dump(modelo, os.path.join(CARPETA_MODELOS, "modelo_guante.pkl"))
    print(f"üíæ Modelo guardado en {CARPETA_MODELOS}/modelo_guante.pkl")

# ==============================
# === FUNCI√ìN: PREDICCI√ìN EN TIEMPO REAL ===
# ==============================
def predecir_tiempo_real():
    ruta_modelo = os.path.join(CARPETA_MODELOS, "modelo_guante.pkl")
    if not os.path.exists(ruta_modelo):
        print("‚ö†Ô∏è No existe modelo entrenado. Ejecuta la opci√≥n 2 primero.")
        return

    modelo = joblib.load(ruta_modelo)
    puerto = input(f"üîå Puerto serial [{PUERTO}]: ").strip() or PUERTO
    ser = serial.Serial(puerto, BAUDIOS)
    time.sleep(2)

    ventana = deque(maxlen=5)  # votaci√≥n deslizante
    umbral_confianza = 0.60

    print("\nüîç Detecci√≥n en tiempo real con votaci√≥n (Ctrl + C para detener)\n")
    try:
        while True:
            linea = ser.readline().decode().strip()
            if not linea:
                continue
            try:
                valores = np.array([float(v) for v in linea.split(",")])
                if len(valores) != 5:
                    continue

                df_temp = pd.DataFrame([valores], columns=["Menique","Anular","Medio","Indice","Gordo"])
                X_temp = generar_features(pd.concat([df_temp, df_temp], ignore_index=True)).iloc[1:].values

                probas = modelo.predict_proba(X_temp)[0]
                pred_idx = np.argmax(probas)
                pred = modelo.classes_[pred_idx]
                conf = probas[pred_idx]

                if conf >= umbral_confianza:
                    ventana.append(pred)
                    final = max(set(ventana), key=ventana.count)
                    print(f"üëâ Letra detectada: {final}  (conf: {conf:.2f})")
                else:
                    print(f"ü§î Se√±al incierta (conf: {conf:.2f})")

                time.sleep(1.5)  # delay entre inferencias
            except Exception as e:
                print("‚ö†Ô∏è Error de lectura:", e)
                continue
    except KeyboardInterrupt:
        print("\nüõë Detecci√≥n detenida manualmente.")
        ser.close()

# ==============================
# === MEN√ö PRINCIPAL ===
# ==============================
def menu():
    while True:
        print("\n===============================")
        print("üß§ GUANTE INTELIGENTE ‚Äî IA TRAINER (MEJORADO)")
        print("===============================")
        print("1Ô∏è‚É£ Recolectar datos (A‚ÄìF, 400 muestras)")
        print("2Ô∏è‚É£ Entrenar modelo mejorado (SVC + features)")
        print("3Ô∏è‚É£ Detecci√≥n en tiempo real (votaci√≥n + umbral)")
        print("4Ô∏è‚É£ Salir")
        opcion = input("Selecciona una opci√≥n: ").strip()

        if opcion == "1":
            recolectar_datos()
        elif opcion == "2":
            entrenar_modelo()
        elif opcion == "3":
            predecir_tiempo_real()
        elif opcion == "4":
            print("üëã Saliendo del sistema...")
            break
        else:
            print("‚ö†Ô∏è Opci√≥n no v√°lida. Intenta nuevamente.")

if __name__ == "__main__":
    menu()
